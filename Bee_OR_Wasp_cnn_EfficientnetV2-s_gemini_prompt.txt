https://colab.research.google.com/drive/1Nd8ULsTJrB0JLqd89DZJLPVPsWBSNbEE?usp=sharing
- train

https://colab.research.google.com/drive/1rlKk48Gcr08mTINflOy8rftssw2umAsP?usp=sharing
- predict


import kagglehub

# Download latest version
path = kagglehub.dataset_download("jerzydziewierz/bee-vs-wasp")

print("Path to dataset files:", path)


ì´ê±° ë°ì´í„° ë°›ê³ , í˜„ì¬ í”„ë¡œì íŠ¸ê²½ë¡œ/dataset ìœ¼ë¡œ ì˜®ê²¨ì¤˜

---------------

import kagglehub
import shutil
import os

# 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì„ì‹œ ê²½ë¡œë¡œ ì €ì¥ë¨)
tmp_path = kagglehub.dataset_download("jerzydziewierz/bee-vs-wasp")
print("ì„ì‹œ ì €ì¥ ê²½ë¡œ:", tmp_path)

# 2. ëª©ì ì§€ ê²½ë¡œ ì„¤ì • (í˜„ì¬ í”„ë¡œì íŠ¸ ê²½ë¡œ/dataset)
target_path = os.path.join(os.getcwd(), "dataset")

# 3. í´ë” ì´ë™ ë¡œì§
try:
Â  Â  if not os.path.exists(target_path):
Â  Â  Â  Â  # ëª©ì ì§€ í´ë”ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ì´ë™
Â  Â  Â  Â  shutil.move(tmp_path, target_path)
Â  Â  Â  Â  print(f"ì„±ê³µ: ë°ì´í„°ë¥¼ {target_path}ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
Â  Â  else:
Â  Â  Â  Â  # ì´ë¯¸ í´ë”ê°€ ìˆëŠ” ê²½ìš° ë‚´ë¶€ íŒŒì¼ë“¤ë§Œ ë³µì‚¬/ì´ë™
Â  Â  Â  Â  print(f"ì•Œë¦¼: '{target_path}' í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‚´ë¶€ íŒŒì¼ì„ ë³‘í•©í•©ë‹ˆë‹¤.")
Â  Â  Â  Â  for item in os.listdir(tmp_path):
Â  Â  Â  Â  Â  Â  s = os.path.join(tmp_path, item)
Â  Â  Â  Â  Â  Â  d = os.path.join(target_path, item)
Â  Â  Â  Â  Â  Â  if os.path.isdir(s):
Â  Â  Â  Â  Â  Â  Â  Â  shutil.copytree(s, d, dirs_exist_ok=True)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  shutil.copy2(s, d)
Â  Â  Â  Â  print("ì„±ê³µ: íŒŒì¼ ì´ë™ ì™„ë£Œ.")
except Exception as e:
Â  Â  print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

dataset í´ë”ê°€ ìˆìœ¼ë©´ ë°›ì§€ ì•ŠëŠ” ì½”ë“œë„ ì¶”ê°€ í•´ì£¼ê³ 


--------------------------


í´ë” ê°œíŒìœ¼ë¡œ ë˜ìˆë„¤.

bee1, bee2 ì–˜ë„¤ëŠ” dataset/bee í´ë”ë¡œ í•©ì³ì£¼ê³ ,
wasp1,wasp2 ì–˜ë„¤ëŠ” dataset/wasp í´ë”ë¡œ í•©ì³ì£¼ê³ ,
other_insect ì–˜ëŠ” dataset/other_insectë¡œ í•©ì³ì£¼ê³ 

ì‘ì—…í•´ì¤˜

-------------------------

í•™ìŠµìš©(train)ê³¼ ê²€ì¦ìš©(val) í´ë”ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ ì§„í–‰


--------------------------


import os
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 1. ê²½ë¡œ ì„¤ì •
data_dir = os.path.join(os.getcwd(), "dataset")

# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì • (Transforms)
# í•™ìŠµìš©ì€ ë°ì´í„° ì¦ê°•(Augmentation)ì„ ì•½ê°„ ì£¼ê³ , ê²€ì¦ìš©ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
data_transforms = {
Â  Â  'train': transforms.Compose([
Â  Â  Â  Â  transforms.Resize((224, 224)),Â  Â  Â  Â  # ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ í¬ê¸° ì¡°ì ˆ (ì¼ë°˜ì ìœ¼ë¡œ 224)
Â  Â  Â  Â  transforms.RandomHorizontalFlip(),Â  Â  # ì¢Œìš° ë°˜ì „ (í•™ìŠµ ë°ì´í„° ëŠ˜ë¦¬ê¸° íš¨ê³¼)
Â  Â  Â  Â  transforms.ToTensor(),Â  Â  Â  Â  Â  Â  Â  Â  # ì´ë¯¸ì§€ë¥¼ í…ì„œ(0~1)ë¡œ ë³€í™˜
Â  Â  Â  Â  transforms.Normalize([0.485, 0.456, 0.406],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [0.229, 0.224, 0.225]) # ImageNet ì •ê·œí™” í‘œì¤€ê°’
Â  Â  ]),
Â  Â  'val': transforms.Compose([
Â  Â  Â  Â  transforms.Resize((224, 224)),
Â  Â  Â  Â  transforms.ToTensor(),
Â  Â  Â  Â  transforms.Normalize([0.485, 0.456, 0.406],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [0.229, 0.224, 0.225])
Â  Â  ]),
}

# 3. ImageFolderë¡œ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
image_datasets = {
Â  Â  x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])
Â  Â  for x in ['train', 'val']
}

# 4. DataLoaderë¡œ ë°°ì¹˜ ë§Œë“¤ê¸° (í•™ìŠµìš©ì€ ì„ê¸°(Shuffle) í•„ìˆ˜)
dataloaders = {
Â  Â  x: DataLoader(image_datasets[x], batch_size=32, shuffle=(x == 'train'), num_workers=2)
Â  Â  for x in ['train', 'val']
}

# 5. ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸
class_names = image_datasets['train'].classes
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}

print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
print(f"ğŸ“Œ í´ë˜ìŠ¤ ëª©ë¡: {class_names}")
print(f"ğŸ“Œ ë°ì´í„° ê°œìˆ˜: {dataset_sizes}")

# --- ì˜ ë¶ˆëŸ¬ì™€ì¡ŒëŠ”ì§€ ë°°ì¹˜ í•˜ë‚˜ë§Œ êº¼ë‚´ì„œ í™•ì¸ ---
inputs, classes = next(iter(dataloaders['train']))
print(f"ğŸ“¦ ë°°ì¹˜(Batch) í˜•íƒœ í™•ì¸ - ì´ë¯¸ì§€: {inputs.shape}, ë¼ë²¨: {classes.shape}")

ë‚´ê°€ efficientnetv2-s ì´ê±¸ë¡œ ë‚˜ì¤‘ì— ì´ë¯¸ì§€ ë¶„ë¥˜ í• ê±´ë°, ì„¤ì • ë§ëŠ”ê±°ëƒ?
bee or wasp êµ¬ë¶„ìš© ë°ì´í„° ì¦ê°•ë„ ë§ëŠ”ê±°ëƒ?


-----------------------



ì•„ëƒì•„ëƒ. crop í•˜ì§€ë§ˆ. efficientnetv2-s ì˜ ê¶Œì¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¡œ ê°€ì•¼í•´.

ì™œ cropì„ ì•ˆí•˜ëŠ”ì§€ ì•Œì•„?
ì‹¤ì œ ì‚¬ì§„ì—ì„œ beeê°€ centerì— ìˆë‹¤ëŠ” ë³´ì¥ì´ ìˆì–´?


------------------------


ì´ì œ efficientnetv2-s ë¥¼ ì´ìš©í•´ì„œ ëª¨ë¸ í›ˆë ¨í•˜ëŠ” ì½”ë“œ ì¤˜.

ê²°ê³¼ë¥¼ 0,1,2 ì´ë ‡ê²Œ ë³´ë©´ ëª¨ë¥´ë‹ˆê¹ class ì´ë¦„ë„ ê°™ì´ ì €ì¥ë˜ê²Œ í•´ì¤˜.


----------------------------


import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights
import time
import copy

# 1. ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ê¶Œì¥)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ í•™ìŠµ ì¥ì¹˜: {device}")

# 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Pre-trained Weights ì‚¬ìš©)
print("ğŸ—ï¸ EfficientNetV2-S ëª¨ë¸ ë¡œë”© ì¤‘...")
weights = EfficientNet_V2_S_Weights.DEFAULT
model = efficientnet_v2_s(weights=weights)

# 3. ë¶„ë¥˜ê¸°(Classifier) êµì²´
# ì›ë˜ EfficientNetì€ 1000ê°œì˜ í´ë˜ìŠ¤ë¥¼ ì¶œë ¥í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” 3ê°œ(bee, wasp, other)ê°€ í•„ìš”í•¨
num_ftrs = model.classifier[1].in_features
class_names = image_datasets['train'].classes # ['bee', 'other_insect', 'wasp']

# ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ ìš°ë¦¬ ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •
model.classifier[1] = nn.Linear(num_ftrs, len(class_names))

model = model.to(device)

# 4. ì†ì‹¤í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²• ì„¤ì •
criterion = nn.CrossEntropyLoss()

# íŒŒì¸íŠœë‹(Fine-tuning)ì´ë¯€ë¡œ í•™ìŠµë¥ (lr)ì„ ë‚®ê²Œ ì¡ìŠµë‹ˆë‹¤ (0.0001 ì¶”ì²œ)
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# 5. í•™ìŠµ í•¨ìˆ˜ ì •ì˜
def train_model(model, criterion, optimizer, num_epochs=10):
Â  Â  since = time.time()

Â  Â  best_model_wts = copy.deepcopy(model.state_dict())
Â  Â  best_acc = 0.0

Â  Â  print(f"\nğŸ”¥ í•™ìŠµ ì‹œì‘ (ì´ {num_epochs} Epochs)")
Â  Â  print("-" * 20)

Â  Â  for epoch in range(num_epochs):
Â  Â  Â  Â  print(f'Epoch {epoch+1}/{num_epochs}')
Â  Â  Â  Â  
Â  Â  Â  Â  # ê° ì—í¬í¬ë§ˆë‹¤ í•™ìŠµ(train)ê³¼ ê²€ì¦(val) ë‹¨ê³„ ì§„í–‰
Â  Â  Â  Â  for phase in ['train', 'val']:
Â  Â  Â  Â  Â  Â  if phase == 'train':
Â  Â  Â  Â  Â  Â  Â  Â  model.train() Â # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  model.eval() Â  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

Â  Â  Â  Â  Â  Â  running_loss = 0.0
Â  Â  Â  Â  Â  Â  running_corrects = 0

Â  Â  Â  Â  Â  Â  # ë°ì´í„° ë°˜ë³µ (Batch ë‹¨ìœ„)
Â  Â  Â  Â  Â  Â  for inputs, labels in dataloaders[phase]:
Â  Â  Â  Â  Â  Â  Â  Â  inputs = inputs.to(device)
Â  Â  Â  Â  Â  Â  Â  Â  labels = labels.to(device)

Â  Â  Â  Â  Â  Â  Â  Â  optimizer.zero_grad() # ê¸°ìš¸ê¸° ì´ˆê¸°í™”

Â  Â  Â  Â  Â  Â  Â  Â  # ìˆœì „íŒŒ (Forward)
Â  Â  Â  Â  Â  Â  Â  Â  with torch.set_grad_enabled(phase == 'train'):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  outputs = model(inputs)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  _, preds = torch.max(outputs, 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  loss = criterion(outputs, labels)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ì—­ì „íŒŒ (Backward) - í•™ìŠµ ë‹¨ê³„ì—ì„œë§Œ
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if phase == 'train':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  loss.backward()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  optimizer.step()

Â  Â  Â  Â  Â  Â  Â  Â  # í†µê³„ ê³„ì‚°
Â  Â  Â  Â  Â  Â  Â  Â  running_loss += loss.item() * inputs.size(0)
Â  Â  Â  Â  Â  Â  Â  Â  running_corrects += torch.sum(preds == labels.data)

Â  Â  Â  Â  Â  Â  epoch_loss = running_loss / dataset_sizes[phase]
Â  Â  Â  Â  Â  Â  epoch_acc = running_corrects.double() / dataset_sizes[phase]

Â  Â  Â  Â  Â  Â  print(f' Â {phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

Â  Â  Â  Â  Â  Â  # ê²€ì¦ ì •í™•ë„ê°€ ë†’ìœ¼ë©´ ëª¨ë¸ ì €ì¥ (Best Model ê°±ì‹ )
Â  Â  Â  Â  Â  Â  if phase == 'val' and epoch_acc > best_acc:
Â  Â  Â  Â  Â  Â  Â  Â  best_acc = epoch_acc
Â  Â  Â  Â  Â  Â  Â  Â  best_model_wts = copy.deepcopy(model.state_dict())
Â  Â  Â  Â  Â  Â  Â  Â  print(f" Â  Â âœ¨ ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! (Acc: {best_acc:.4f})")

Â  Â  Â  Â  print()

Â  Â  time_elapsed = time.time() - since
Â  Â  print(f'â±ï¸ í•™ìŠµ ì™„ë£Œ: {time_elapsed // 60:.0f}ë¶„ {time_elapsed % 60:.0f}ì´ˆ ì†Œìš”')
Â  Â  print(f'ğŸ† ìµœê³  ê²€ì¦ ì •í™•ë„: {best_acc:.4f}')

Â  Â  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
Â  Â  model.load_state_dict(best_model_wts)
Â  Â  return model

# 6. í•™ìŠµ ì‹¤í–‰ (ì˜ˆ: 5 Epochë§Œ í…ŒìŠ¤íŠ¸ë¡œ ëŒë ¤ë´„)
# GPUê°€ ì—†ë‹¤ë©´ num_epochsë¥¼ 1ë¡œ ì¤„ì´ì„¸ìš”. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.
trained_model = train_model(model, criterion, optimizer, num_epochs=5)

# 7. ëª¨ë¸ ë° í´ë˜ìŠ¤ ì •ë³´ ì €ì¥
save_path = 'bee_wasp_efficientnetv2.pth'
print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘... ({save_path})")

torch.save({
Â  Â  'model_state_dict': trained_model.state_dict(),
Â  Â  'class_names': class_names, Â # ì—¬ê¸°ì— í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°™ì´ ì €ì¥í•¨!
Â  Â  'input_size': 384 Â  Â  Â  Â  Â  Â # ë‚˜ì¤‘ì— ì°¸ê³ í•˜ë ¤ê³  ì…ë ¥ í¬ê¸°ë„ ì €ì¥
}, save_path)

print("âœ… ì €ì¥ ì™„ë£Œ. ì´ì œ ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¬ ë•Œ 0,1,2 ëŒ€ì‹  ì´ë¦„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


ì´ê±° í›ˆë ¨ì¤‘ì— train acc val acc ë‹¤ ë‚˜ì˜¤ëŠ”ê±°ì•¼?


--------------------



# 7. ëª¨ë¸ ë° í´ë˜ìŠ¤ ì •ë³´ ì €ì¥
save_path = 'bee_wasp_efficientnetv2.pth'
print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘... ({save_path})")

torch.save({
Â  Â  'model_state_dict': trained_model.state_dict(),
Â  Â  'class_names': class_names, Â # ì—¬ê¸°ì— í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°™ì´ ì €ì¥í•¨!
Â  Â  'input_size': 384 Â  Â  Â  Â  Â  Â # ë‚˜ì¤‘ì— ì°¸ê³ í•˜ë ¤ê³  ì…ë ¥ í¬ê¸°ë„ ì €ì¥
}, save_path)

print("âœ… ì €ì¥ ì™„ë£Œ. ì´ì œ ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¬ ë•Œ 0,1,2 ëŒ€ì‹  ì´ë¦„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

ì´ê±° ìµœì¢…ëª¨ë¸ ë‚´ê°€ ì •í•œ google drive ì— ì €ì¥í•˜ê³  ì‹¶ì€ë° ì–´ìºí•¨?